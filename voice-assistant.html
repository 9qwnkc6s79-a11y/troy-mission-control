<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OpenClaw Voice Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #1e1e1e 0%, #2d2d2d 100%);
            color: white;
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .container {
            max-width: 800px;
            width: 90%;
            text-align: center;
            padding: 2rem;
        }

        .logo {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 1rem;
            background: linear-gradient(45deg, #00a8ff, #0078ff);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .status {
            font-size: 1.2rem;
            margin-bottom: 2rem;
            opacity: 0.8;
        }

        .mic-container {
            position: relative;
            margin: 3rem auto;
            width: 150px;
            height: 150px;
        }

        .mic-button {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            border: 3px solid #333;
            background: linear-gradient(135deg, #2c2c2c 0%, #404040 100%);
            color: white;
            font-size: 3rem;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }

        .mic-button:hover {
            transform: scale(1.05);
            background: linear-gradient(135deg, #404040 0%, #505050 100%);
        }

        .mic-button.listening {
            background: linear-gradient(135deg, #ff4757 0%, #ff3742 100%);
            border-color: #ff4757;
            animation: pulse 1.5s infinite;
        }

        .mic-button.processing {
            background: linear-gradient(135deg, #ffa502 0%, #ff6348 100%);
            border-color: #ffa502;
        }

        .mic-button.speaking {
            background: linear-gradient(135deg, #00a8ff 0%, #0078ff 100%);
            border-color: #00a8ff;
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(255, 71, 87, 0.7); }
            70% { box-shadow: 0 0 0 20px rgba(255, 71, 87, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 71, 87, 0); }
        }

        .visualizer {
            position: absolute;
            bottom: -50px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            align-items: flex-end;
            height: 40px;
            gap: 3px;
        }

        .visualizer-bar {
            width: 4px;
            background: #00a8ff;
            border-radius: 2px;
            transition: height 0.1s ease;
        }

        .conversation {
            margin-top: 3rem;
            max-height: 300px;
            overflow-y: auto;
            padding: 1rem;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 12px;
            text-align: left;
        }

        .message {
            margin: 1rem 0;
            padding: 0.8rem 1.2rem;
            border-radius: 18px;
            max-width: 80%;
            line-height: 1.4;
        }

        .message.user {
            background: linear-gradient(135deg, #00a8ff 0%, #0078ff 100%);
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            background: rgba(255, 255, 255, 0.1);
            margin-right: auto;
        }

        .controls {
            margin-top: 2rem;
            display: flex;
            gap: 1rem;
            justify-content: center;
            flex-wrap: wrap;
        }

        .control-btn {
            padding: 0.8rem 1.5rem;
            border: none;
            border-radius: 25px;
            background: rgba(255, 255, 255, 0.1);
            color: white;
            cursor: pointer;
            transition: all 0.3s ease;
            font-size: 0.9rem;
        }

        .control-btn:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
        }

        .error {
            color: #ff4757;
            margin-top: 1rem;
            padding: 1rem;
            background: rgba(255, 71, 87, 0.1);
            border-radius: 8px;
        }

        .settings {
            position: absolute;
            top: 20px;
            right: 20px;
        }

        .settings-btn {
            background: none;
            border: none;
            color: white;
            font-size: 1.5rem;
            cursor: pointer;
            opacity: 0.7;
        }

        .settings-panel {
            position: absolute;
            top: 50px;
            right: 0;
            background: #2c2c2c;
            padding: 1rem;
            border-radius: 8px;
            min-width: 250px;
            display: none;
        }

        .settings-panel.show {
            display: block;
        }

        .setting-group {
            margin-bottom: 1rem;
        }

        .setting-group label {
            display: block;
            margin-bottom: 0.5rem;
            font-size: 0.9rem;
            opacity: 0.8;
        }

        .setting-group select,
        .setting-group input {
            width: 100%;
            padding: 0.5rem;
            border-radius: 4px;
            border: 1px solid #444;
            background: #1e1e1e;
            color: white;
        }

        .hidden {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="settings">
            <button class="settings-btn" onclick="toggleSettings()">‚öôÔ∏è</button>
            <div class="settings-panel" id="settingsPanel">
                <div class="setting-group">
                    <label for="apiKeyInput">OpenAI API Key:</label>
                    <input type="password" id="apiKeyInput" placeholder="sk-..." onchange="saveApiKey()">
                </div>
                <div class="setting-group">
                    <label for="openclaw-url">OpenClaw URL:</label>
                    <input type="text" id="openclaw-url" value="ws://localhost:8080/ws" onchange="saveOpenClawUrl()">
                </div>
                <div class="setting-group">
                    <label for="voice-select">Assistant Voice:</label>
                    <select id="voice-select" onchange="saveVoiceSelection()">
                        <option value="alloy">Alloy</option>
                        <option value="echo">Echo</option>
                        <option value="fable">Fable</option>
                        <option value="onyx">Onyx</option>
                        <option value="nova" selected>Nova</option>
                        <option value="shimmer">Shimmer</option>
                    </select>
                </div>
            </div>
        </div>

        <h1 class="logo">OpenClaw Voice</h1>
        <div class="status" id="status">Press and hold the microphone to speak</div>

        <div class="mic-container">
            <button class="mic-button" id="micButton">üé§</button>
            <div class="visualizer" id="visualizer">
                <!-- Audio visualizer bars will be added dynamically -->
            </div>
        </div>

        <div class="conversation" id="conversation">
            <div class="message assistant">
                Hi! I'm your OpenClaw voice assistant. Press and hold the microphone to start talking.
            </div>
        </div>

        <div class="controls">
            <button class="control-btn" onclick="clearConversation()">Clear Chat</button>
            <button class="control-btn" onclick="testConnection()">Test Connection</button>
            <button class="control-btn" onclick="toggleContinuousMode()">Continuous Mode: <span id="continuousStatus">OFF</span></button>
        </div>

        <div class="error hidden" id="errorDiv"></div>
    </div>

    <script>
        // Configuration
        let config = {
            apiKey: localStorage.getItem('openai-api-key') || '',
            openclawUrl: localStorage.getItem('openclaw-url') || 'ws://localhost:8080/ws',
            selectedVoice: localStorage.getItem('selected-voice') || 'nova'
        };

        // State
        let isListening = false;
        let isProcessing = false;
        let isSpeaking = false;
        let continuousMode = false;
        let mediaRecorder = null;
        let audioChunks = [];
        let openclawSocket = null;
        let currentAudio = null;

        // UI Elements
        const micButton = document.getElementById('micButton');
        const status = document.getElementById('status');
        const conversation = document.getElementById('conversation');
        const errorDiv = document.getElementById('errorDiv');
        const visualizer = document.getElementById('visualizer');

        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            initializeVisualizer();
            loadSettings();
            connectToOpenClaw();
        });

        function initializeVisualizer() {
            // Create visualizer bars
            for (let i = 0; i < 20; i++) {
                const bar = document.createElement('div');
                bar.className = 'visualizer-bar';
                bar.style.height = '2px';
                visualizer.appendChild(bar);
            }
        }

        function loadSettings() {
            document.getElementById('apiKeyInput').value = config.apiKey;
            document.getElementById('openclaw-url').value = config.openclawUrl;
            document.getElementById('voice-select').value = config.selectedVoice;
        }

        function saveApiKey() {
            config.apiKey = document.getElementById('apiKeyInput').value;
            localStorage.setItem('openai-api-key', config.apiKey);
        }

        function saveOpenClawUrl() {
            config.openclawUrl = document.getElementById('openclaw-url').value;
            localStorage.setItem('openclaw-url', config.openclawUrl);
            connectToOpenClaw();
        }

        function saveVoiceSelection() {
            config.selectedVoice = document.getElementById('voice-select').value;
            localStorage.setItem('selected-voice', config.selectedVoice);
        }

        function connectToOpenClaw() {
            try {
                if (openclawSocket) {
                    openclawSocket.close();
                }
                
                openclawSocket = new WebSocket(config.openclawUrl);
                
                openclawSocket.onopen = function() {
                    updateStatus('Connected to OpenClaw');
                    hideError();
                };
                
                openclawSocket.onmessage = function(event) {
                    const response = JSON.parse(event.data);
                    if (response.text) {
                        addMessage(response.text, 'assistant');
                        speakText(response.text);
                    }
                };
                
                openclawSocket.onerror = function() {
                    showError('Failed to connect to OpenClaw. Using fallback mode.');
                };
                
                openclawSocket.onclose = function() {
                    updateStatus('Disconnected from OpenClaw');
                };
                
            } catch (error) {
                showError('WebSocket connection failed: ' + error.message);
            }
        }

        // Microphone handling
        micButton.addEventListener('mousedown', startListening);
        micButton.addEventListener('mouseup', stopListening);
        micButton.addEventListener('mouseleave', stopListening);

        // Touch support
        micButton.addEventListener('touchstart', startListening);
        micButton.addEventListener('touchend', stopListening);

        async function startListening() {
            if (isProcessing || isSpeaking) return;
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                isListening = true;
                audioChunks = [];
                
                mediaRecorder = new MediaRecorder(stream);
                mediaRecorder.start();
                
                mediaRecorder.addEventListener('dataavailable', event => {
                    audioChunks.push(event.data);
                });
                
                micButton.classList.add('listening');
                updateStatus('Listening... Release to send');
                
                // Start audio visualization
                startAudioVisualization(stream);
                
            } catch (error) {
                showError('Microphone access denied: ' + error.message);
            }
        }

        function stopListening() {
            if (!isListening || !mediaRecorder) return;
            
            isListening = false;
            mediaRecorder.stop();
            
            micButton.classList.remove('listening');
            micButton.classList.add('processing');
            updateStatus('Processing...');
            
            mediaRecorder.addEventListener('stop', processAudio);
        }

        async function processAudio() {
            isProcessing = true;
            
            try {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                const transcription = await transcribeAudio(audioBlob);
                
                if (transcription && transcription.trim()) {
                    addMessage(transcription, 'user');
                    await sendToOpenClaw(transcription);
                } else {
                    updateStatus('No speech detected. Try again.');
                }
                
            } catch (error) {
                showError('Error processing audio: ' + error.message);
            } finally {
                isProcessing = false;
                micButton.classList.remove('processing');
                updateStatus('Press and hold to speak');
            }
        }

        async function transcribeAudio(audioBlob) {
            if (!config.apiKey) {
                throw new Error('OpenAI API key not configured');
            }
            
            const formData = new FormData();
            formData.append('file', audioBlob, 'audio.wav');
            formData.append('model', 'whisper-1');
            
            const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${config.apiKey}`
                },
                body: formData
            });
            
            if (!response.ok) {
                const error = await response.json();
                throw new Error(error.error?.message || 'Transcription failed');
            }
            
            const result = await response.json();
            return result.text;
        }

        async function sendToOpenClaw(message) {
            if (openclawSocket && openclawSocket.readyState === WebSocket.OPEN) {
                // Send to OpenClaw
                openclawSocket.send(JSON.stringify({
                    type: 'voice_message',
                    content: message,
                    timestamp: new Date().toISOString()
                }));
            } else {
                // Fallback: Use OpenAI directly
                const response = await getChatResponse(message);
                addMessage(response, 'assistant');
                speakText(response);
            }
        }

        async function getChatResponse(message) {
            if (!config.apiKey) {
                throw new Error('OpenAI API key not configured');
            }
            
            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${config.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'gpt-4',
                    messages: [
                        {
                            role: 'system',
                            content: 'You are a helpful voice assistant. Give concise, natural responses suitable for speech.'
                        },
                        {
                            role: 'user',
                            content: message
                        }
                    ],
                    max_tokens: 150
                })
            });
            
            if (!response.ok) {
                throw new Error('Chat API request failed');
            }
            
            const result = await response.json();
            return result.choices[0].message.content;
        }

        async function speakText(text) {
            if (currentAudio) {
                currentAudio.pause();
            }
            
            isSpeaking = true;
            micButton.classList.add('speaking');
            updateStatus('Speaking...');
            
            try {
                if (config.apiKey && 'speechSynthesis' in window) {
                    // Try OpenAI TTS first, fallback to Web Speech API
                    try {
                        await speakWithOpenAI(text);
                    } catch (error) {
                        console.warn('OpenAI TTS failed, using Web Speech API:', error);
                        speakWithWebAPI(text);
                    }
                } else {
                    speakWithWebAPI(text);
                }
                
            } catch (error) {
                showError('Speech synthesis error: ' + error.message);
            } finally {
                isSpeaking = false;
                micButton.classList.remove('speaking');
                updateStatus('Press and hold to speak');
                
                if (continuousMode) {
                    setTimeout(() => {
                        if (!isListening && !isProcessing) {
                            startListening();
                        }
                    }, 1000);
                }
            }
        }

        async function speakWithOpenAI(text) {
            const response = await fetch('https://api.openai.com/v1/audio/speech', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${config.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'tts-1',
                    input: text,
                    voice: config.selectedVoice,
                    speed: 1.0
                })
            });
            
            if (!response.ok) {
                throw new Error('TTS API request failed');
            }
            
            const audioBlob = await response.blob();
            const audioUrl = URL.createObjectURL(audioBlob);
            
            currentAudio = new Audio(audioUrl);
            currentAudio.play();
            
            return new Promise((resolve, reject) => {
                currentAudio.onended = resolve;
                currentAudio.onerror = reject;
            });
        }

        function speakWithWebAPI(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 0.9;
            utterance.pitch = 1.0;
            
            return new Promise((resolve) => {
                utterance.onend = resolve;
                speechSynthesis.speak(utterance);
            });
        }

        function startAudioVisualization(stream) {
            const audioContext = new AudioContext();
            const analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(stream);
            microphone.connect(analyser);
            
            analyser.fftSize = 64;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            function animate() {
                if (isListening) {
                    analyser.getByteFrequencyData(dataArray);
                    
                    const bars = visualizer.querySelectorAll('.visualizer-bar');
                    bars.forEach((bar, index) => {
                        const value = dataArray[index] || 0;
                        const height = Math.max(2, (value / 255) * 40);
                        bar.style.height = height + 'px';
                    });
                    
                    requestAnimationFrame(animate);
                } else {
                    // Reset bars
                    const bars = visualizer.querySelectorAll('.visualizer-bar');
                    bars.forEach(bar => {
                        bar.style.height = '2px';
                    });
                }
            }
            
            animate();
        }

        // UI Helper Functions
        function addMessage(text, sender) {
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}`;
            messageDiv.textContent = text;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function updateStatus(text) {
            status.textContent = text;
        }

        function showError(text) {
            errorDiv.textContent = text;
            errorDiv.classList.remove('hidden');
            setTimeout(() => hideError(), 5000);
        }

        function hideError() {
            errorDiv.classList.add('hidden');
        }

        function clearConversation() {
            conversation.innerHTML = '<div class="message assistant">Chat cleared. How can I help you?</div>';
        }

        function testConnection() {
            if (openclawSocket && openclawSocket.readyState === WebSocket.OPEN) {
                showError('‚úÖ OpenClaw connection is working!');
            } else {
                showError('‚ùå OpenClaw connection failed. Check your settings.');
            }
        }

        function toggleContinuousMode() {
            continuousMode = !continuousMode;
            document.getElementById('continuousStatus').textContent = continuousMode ? 'ON' : 'OFF';
            updateStatus(continuousMode ? 'Continuous mode enabled' : 'Continuous mode disabled');
        }

        function toggleSettings() {
            const panel = document.getElementById('settingsPanel');
            panel.classList.toggle('show');
        }

        // Close settings panel when clicking outside
        document.addEventListener('click', function(event) {
            const panel = document.getElementById('settingsPanel');
            const settingsBtn = document.querySelector('.settings-btn');
            
            if (!panel.contains(event.target) && !settingsBtn.contains(event.target)) {
                panel.classList.remove('show');
            }
        });
    </script>
</body>
</html>